{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpWf7XC91xdpQYU4GkQFPv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laxmimurali/Adversarial/blob/main/AdversarialNoise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adversarial Noise"
      ],
      "metadata": {
        "id": "OsCyaC7BA3Fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import standard libraries**"
      ],
      "metadata": {
        "id": "Slcg_2QzA_p_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TEV00UJyAuQn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import scipy.linalg\n",
        "from PIL import Image\n",
        "from fastai.vision.all import *\n",
        "import shutil\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "\n",
        "# Torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets.utils import download_url"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fetching the device that will be used throughout this notebook.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z2iZIpgNVx-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
        "print(\"Using device\", device)"
      ],
      "metadata": {
        "id": "fUMMpgQRVylR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12704775-ff8b-450c-eec6-af48a357b6b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the CNN pretrained on ImageNet**"
      ],
      "metadata": {
        "id": "YdRdiLAJBaB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = models.resnet50(weights='IMAGENET1K_V1')\n",
        "resnet50.eval()  # cuda preferable\n",
        "for p in resnet50.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "resnet50.to(device)"
      ],
      "metadata": {
        "id": "B_NETTjMBfDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea78acb8-006e-40fe-bbbf-fb5c914e4d36"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**User input**: Change the name of file to the user input filename"
      ],
      "metadata": {
        "id": "tTkssv4VZE4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename1 = '/content/dogphoto_GR.jpg'"
      ],
      "metadata": {
        "id": "kvIP_TNhYC7B"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Default input**"
      ],
      "metadata": {
        "id": "Z6bjSrEmZL7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "db = download_url(dataset_url,'.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWinx0TqR5mc",
        "outputId": "379f4607-62ad-47c8-92c8-8a893c48aace"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg to ./dog.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 661378/661378 [00:00<00:00, 29854820.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "1.   **Mean and Std from ImageNet**\n",
        "2.   **Preprocess data**\n",
        "3.  **Add batch dimensions**\n",
        "4. **Convert to variable**\n",
        "\n"
      ],
      "metadata": {
        "id": "QTddDLZoSPlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process(filename):\n",
        "  NORM_MEAN = np.array([0.485, 0.456, 0.406])\n",
        "  NORM_STD = np.array([0.229, 0.224, 0.225])\n",
        "  preprocess = transforms.Compose([transforms.Resize(256), # cuts out edges\n",
        "                                 transforms.CenterCrop(224),  # then crop\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize(mean=NORM_MEAN,\n",
        "                                                      std=NORM_STD)\n",
        "                                 ])\n",
        "  input_image = Image.open(filename)\n",
        "  input_tensor = preprocess(input_image)\n",
        "  input_batch = input_tensor.unsqueeze(0)\n",
        "  input_batch = input_batch.to(device)\n",
        "  input_variable = input_batch.clone().detach().requires_grad_(True)\n",
        "  return(input_tensor, input_batch,input_variable)\n"
      ],
      "metadata": {
        "id": "j15IabFISG88"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NORM_MEAN = np.array([0.485, 0.456, 0.406])\n",
        "NORM_STD = np.array([0.229, 0.224, 0.225])\n",
        "input_tensor, input_batch, input_variable= process(filename=filename)"
      ],
      "metadata": {
        "id": "0i0byH72W_O-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download ImageNet labels**\n"
      ],
      "metadata": {
        "id": "mA-x5a5Msm8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwM-43gRtQ6R",
        "outputId": "fa4ba392-d213-4079-a8f3-0dc32433e86b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-11 08:50:35--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "\rimagenet_classes.tx   0%[                    ]       0  --.-KB/s               \rimagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-11 08:50:35 (120 MB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classify the input using the resnet50 model and calculate the probability distribution over all the classes using softmax function**"
      ],
      "metadata": {
        "id": "_BDoEySwk7ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(img, model):\n",
        "  with torch.no_grad():\n",
        "      output = model(img)\n",
        "      #print(output[0])\n",
        "  probabilities = F.softmax(output[0], dim=0)\n",
        "  #print(probabilities)\n",
        "  # Read the categories\n",
        "  with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "      categories = [s.strip() for s in f.readlines()]\n",
        "  # Show top categories per image\n",
        "  top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "  for i in range(top5_prob.size(0)):\n",
        "      print(categories[top5_catid[i]], top5_prob[i].item())\n",
        "  x_label = top5_catid[0]\n",
        "  x_pred = categories[top5_catid[0]]\n",
        "  x_pred_prob = top5_prob[0].item()\n",
        "  return(x_label,x_pred, x_pred_prob)"
      ],
      "metadata": {
        "id": "BzHv5v3OcHYg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_label, x_pred, x_pred_prob = eval(input_batch, resnet50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx8N69u6tkvN",
        "outputId": "e109c6ee-0ce3-429b-83b3-2c4a31d633a1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samoyed 0.8732960224151611\n",
            "Pomeranian 0.03027079813182354\n",
            "white wolf 0.01967117004096508\n",
            "keeshond 0.01107353251427412\n",
            "Eskimo dog 0.009204265661537647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fast Gradient Sign Method (FGSM)\n",
        "\n",
        "One of the first attack strategies proposed is Fast Gradient Sign Method (FGSM), developed by Ian Goodfellow et al. in 2014. Given an image, we create an adversarial example by the following expression:\n",
        "\n",
        "$X^{adv} = X + ϵsign(\\nabla_x J(X, Y_{true})$\n",
        "\n",
        "$X$ : input\n",
        "$X^{adv}$ : adversarial input\n",
        "$ϵ$ : magnitude of adversarial perturbation\n",
        "$\\nabla_x J(X, Y_{true})$ : gradient of loss function wrt to input\n",
        "\n",
        "Resembles SGD\n",
        "\n",
        "Change input in the direction of maximising the loss\n",
        "\n"
      ],
      "metadata": {
        "id": "1fj_AxnPPipb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FGSM(model, img, label, epsilon):\n",
        "  out = model(img) #img needs to be variable\n",
        "\n",
        "  y_true = label\n",
        "  target = torch.tensor(torch.LongTensor([y_true]), requires_grad=False)\n",
        "  print(target)\n",
        "\n",
        "  # Calculate loss by NLL\n",
        "  #loss = torch.nn.CrossEntropyLoss()\n",
        "  loss = -torch.gather(out, 1, target.to(device).unsqueeze(dim=-1))\n",
        "  loss.sum().backward() #calculate gradients of each variable(with requires_grad=True)\n",
        "  # Update image to adversarial example as written above\n",
        "  noise_grad = torch.sign(input_variable.grad.data.to(device)) #calc sign\n",
        "  x_adv = input_variable.data + epsilon * noise_grad #find adv using formula\n",
        "  output_adv = resnet50.forward(torch.tensor(x_adv)) #forward pass on adv\n",
        "  with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "      categories = [s.strip() for s in f.readlines()]\n",
        "  x_adv_pred = categories[torch.max(output_adv.data,1)[1][0]]\n",
        "  adv_probs = F.softmax(output_adv[0], dim=0) #prob distribution over classes\n",
        "  top5_adv_prob, top5_adv_catid = torch.topk(adv_probs, 5)\n",
        "  for i in range(top5_adv_prob.size(0)):\n",
        "      print(categories[top5_adv_catid[i]], top5_adv_prob[i].item())\n",
        "  adv_pred_prob = top5_adv_prob[0].item()\n",
        "  return(noise_grad, x_adv, x_adv_pred, adv_pred_prob)\n",
        "\n",
        "epsilon = 0.07\n",
        "noise_grad, x_adv, x_adv_pred, adv_pred_prob = FGSM(resnet50, input_variable, x_label, epsilon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wCDvLZEP31v",
        "outputId": "c9fe4bef-a4d7-4788-e7fc-ece460f69d8b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([258])\n",
            "West Highland white terrier 0.5609617829322815\n",
            "Scotch terrier 0.057895079255104065\n",
            "wallaby 0.04786724969744682\n",
            "cairn 0.039975229650735855\n",
            "Angora 0.027445361018180847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-81f52723da44>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(torch.LongTensor([y_true]), requires_grad=False)\n",
            "<ipython-input-37-81f52723da44>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  output_adv = resnet50.forward(torch.tensor(x_adv)) #forward pass on adv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization**"
      ],
      "metadata": {
        "id": "6V4paUXMX7tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(x, x_adv, x_grad, epsilon, clean_pred, adv_pred, clean_prob, adv_prob):\n",
        "\n",
        "    x = x.squeeze(0)     #remove batch dimension # B X C H X W ==> C X H X W\n",
        "    x = x.mul(torch.FloatTensor(NORM_STD).view(3,1,1)).add(torch.FloatTensor(NORM_MEAN).view(3,1,1)).numpy()#reverse of normalization op- \"unnormalize\"\n",
        "    x = np.transpose( x , (1,2,0))   # C X H X W  ==>   H X W X C\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    x_adv = x_adv.squeeze(0)\n",
        "    x_adv = x_adv.mul(torch.FloatTensor(NORM_STD).view(3,1,1)).add(torch.FloatTensor(NORM_MEAN).view(3,1,1)).numpy()#reverse of normalization op\n",
        "    x_adv = np.transpose( x_adv , (1,2,0))   # C X H X W  ==>   H X W X C\n",
        "    x_adv = np.clip(x_adv, 0, 1)\n",
        "\n",
        "    x_grad = x_grad.squeeze(0).numpy()\n",
        "    x_grad = np.transpose(x_grad, (1,2,0))\n",
        "    x_grad = np.clip(x_grad, 0, 1)\n",
        "\n",
        "    figure, ax = plt.subplots(1,3, figsize=(18,8))\n",
        "    ax[0].imshow(x)\n",
        "    ax[0].set_title('Input', fontsize=20)\n",
        "\n",
        "\n",
        "    ax[1].imshow(x_grad)\n",
        "    ax[1].set_title('Perturbation', fontsize=20)\n",
        "    ax[1].set_yticklabels([])\n",
        "    ax[1].set_xticklabels([])\n",
        "    ax[1].set_xticks([])\n",
        "    ax[1].set_yticks([])\n",
        "\n",
        "\n",
        "    ax[2].imshow(x_adv)\n",
        "    ax[2].set_title('Adversarial example', fontsize=20)\n",
        "\n",
        "    ax[0].axis('off')\n",
        "    ax[2].axis('off')\n",
        "\n",
        "    ax[0].text(1.1,0.5, \"+{}*\".format(round(epsilon,3)), size=15, ha=\"center\",\n",
        "             transform=ax[0].transAxes)\n",
        "\n",
        "    ax[0].text(0.5,-0.13, \"Prediction: {}\\n Probability: {}\".format(clean_pred, clean_prob*100), size=15, ha=\"center\",\n",
        "         transform=ax[0].transAxes)\n",
        "\n",
        "    ax[1].text(1.1,0.5, \" = \", size=15, ha=\"center\", transform=ax[1].transAxes)\n",
        "\n",
        "    ax[2].text(0.5,-0.13, \"Prediction: {}\\n Probability: {}\".format(adv_pred, adv_prob*100), size=15, ha=\"center\",\n",
        "         transform=ax[2].transAxes)\n",
        "\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gg6wcgVcX9Tl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(input_tensor, x_adv, noise_grad, epsilon, x_pred, x_adv_pred, x_pred_prob, adv_pred_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "rtWRJX7oYRn6",
        "outputId": "cf5dbe36-a66f-4ffb-c2a5-5c29da633603"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-35c8597c3208>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_adv_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pred_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_pred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-0854c1823212>\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(x, x_adv, x_grad, epsilon, clean_pred, adv_pred, clean_prob, adv_prob)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_adv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNORM_STD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNORM_MEAN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#reverse of normalization op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_adv\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# C X H X W  ==>   H X W X C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    }
  ]
}